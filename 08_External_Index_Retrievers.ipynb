{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 - External Index Retrievers üåê\n",
    "\n",
    "## Learning Objectives üéØ\n",
    "\n",
    "In this notebook, you'll learn:\n",
    "\n",
    "1. **What are External Index Retrievers** and how they differ from vector store retrievers\n",
    "2. **ArxivRetriever** - Search and retrieve scholarly articles from arxiv.org\n",
    "3. **WikipediaRetriever** - Access Wikipedia articles for general knowledge\n",
    "4. **TavilySearchAPIRetriever** - Perform real-time internet searches\n",
    "5. **Integration with RAG Chains** - Combine external retrievers with LLMs\n",
    "6. **Best Practices** - When and how to use each retriever effectively\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents üìö\n",
    "\n",
    "1. [Introduction to External Retrievers](#intro)\n",
    "2. [Setup & Installation](#setup)\n",
    "3. [ArxivRetriever - Academic Papers](#arxiv)\n",
    "4. [WikipediaRetriever - General Knowledge](#wikipedia)\n",
    "5. [TavilySearchAPIRetriever - Web Search](#tavily)\n",
    "6. [Integration with RAG Chains](#rag)\n",
    "7. [Comparison & Use Cases](#comparison)\n",
    "8. [Best Practices](#best-practices)\n",
    "9. [Summary & Exercises](#summary)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## 1. Introduction to External Index Retrievers üîç\n",
    "\n",
    "### What are External Index Retrievers?\n",
    "\n",
    "**External Index Retrievers** search over external data sources (e.g., the internet, academic databases, knowledge bases) rather than your local vector store.\n",
    "\n",
    "### Key Differences:\n",
    "\n",
    "| Feature | Vector Store Retrievers | External Index Retrievers |\n",
    "|---------|------------------------|---------------------------|\n",
    "| **Data Source** | Your embedded documents | External databases/APIs |\n",
    "| **Data Freshness** | Static (at indexing time) | Real-time or regularly updated |\n",
    "| **Setup Required** | Embedding + Vector store | API keys (sometimes) |\n",
    "| **Use Cases** | Internal documents, knowledge bases | Current events, academic research, general knowledge |\n",
    "| **Cost** | Embedding cost + storage | API calls (often free tier available) |\n",
    "\n",
    "### When to Use External Retrievers:\n",
    "\n",
    "- ‚úÖ You need **up-to-date information** from the internet\n",
    "- ‚úÖ You want to access **specialized databases** (e.g., academic papers)\n",
    "- ‚úÖ You need **general knowledge** without building a custom knowledge base\n",
    "- ‚úÖ You want to **augment** your local data with external sources\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## 2. Setup & Installation ‚öôÔ∏è\n",
    "\n",
    "### Required Packages\n",
    "\n",
    "All external retrievers are part of `langchain-community`. You'll also need:\n",
    "\n",
    "```bash\n",
    "pip install langchain-community\n",
    "pip install arxiv           # For ArxivRetriever\n",
    "pip install wikipedia       # For WikipediaRetriever\n",
    "pip install tavily-python   # For TavilySearchAPIRetriever\n",
    "```\n",
    "\n",
    "### Environment Variables\n",
    "\n",
    "For TavilySearchAPIRetriever, you'll need an API key:\n",
    "\n",
    "```\n",
    "TAVILY_API_KEY=your_api_key_here\n",
    "```\n",
    "\n",
    "Get your free API key at: https://tavily.com/\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL-NO: 1\n",
    "# Setup: Import required libraries\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Import LangChain components\n",
    "from langchain_community.retrievers import ArxivRetriever, WikipediaRetriever, TavilySearchAPIRetriever\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Verify versions\n",
    "import langchain\n",
    "print(f\"‚úÖ LangChain version: {langchain.__version__}\")\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='arxiv'></a>\n",
    "## 3. ArxivRetriever - Academic Papers üìÑ\n",
    "\n",
    "### üî∞ BEGINNER: What is ArxivRetriever?\n",
    "\n",
    "**ArxivRetriever** searches [arxiv.org](https://arxiv.org), a repository of electronic preprints for research papers in:\n",
    "- Physics\n",
    "- Mathematics\n",
    "- Computer Science\n",
    "- Quantitative Biology\n",
    "- Quantitative Finance\n",
    "- Statistics\n",
    "\n",
    "### Use Cases:\n",
    "- üìö Literature review for research\n",
    "- üß† Getting latest research on AI/ML topics\n",
    "- üìä Finding papers by specific authors\n",
    "- üî¨ Accessing cutting-edge research\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî∞ BEGINNER: Basic ArxivRetriever Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL-NO: 2\n",
    "!uv pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL-NO: 3\n",
    "# Create an ArxivRetriever instance\n",
    "# By default, it returns top 3 documents\n",
    "arxiv_retriever = ArxivRetriever(load_max_docs=3)\n",
    "\n",
    "# Search for papers on \"large language models\"\n",
    "query = \"large language models\"\n",
    "docs = arxiv_retriever.invoke(query)\n",
    "\n",
    "print(f\"üìö Found {len(docs)} papers on '{query}'\\n\")\n",
    "\n",
    "# Display first paper\n",
    "print(\"=\" * 80)\n",
    "print(f\"Title: {docs[0].metadata.get('Title', 'N/A')}\")\n",
    "print(f\"Authors: {docs[0].metadata.get('Authors', 'N/A')}\")\n",
    "print(f\"Published: {docs[0].metadata.get('Published', 'N/A')}\")\n",
    "print(f\"\\nAbstract (first 500 chars):\\n{docs[0].page_content[:500]}...\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Title: {docs[1].metadata.get('Title', 'N/A')}\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Title: {docs[2].metadata.get('Title', 'N/A')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì INTERMEDIATE: Advanced ArxivRetriever Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL-NO: 4\n",
    "# Advanced: Retrieve more documents and explore metadata\n",
    "arxiv_retriever_advanced = ArxivRetriever(\n",
    "    load_max_docs=5,  # Get top 5 papers\n",
    "    load_all_available_meta=True  # Load all metadata\n",
    ")\n",
    "\n",
    "# Search for papers on \"transformers attention mechanism\"\n",
    "query = \"transformers attention mechanism\"\n",
    "docs = arxiv_retriever_advanced.invoke(query)\n",
    "\n",
    "print(f\"üìö Retrieved {len(docs)} papers.\\n\")\n",
    "\n",
    "# Display metadata for all papers\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"{i}. {doc.metadata.get('Title', 'N/A')}\")\n",
    "    print(f\"   Authors: {doc.metadata.get('Authors', 'N/A')}\")\n",
    "    print(f\"   Published: {doc.metadata.get('Published', 'N/A')}\")\n",
    "    print(f\"   Entry ID: {doc.metadata.get('entry_id', 'N/A')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì INTERMEDIATE: Using .batch() for Multiple Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL-NO: 5\n",
    "# Batch processing: Search multiple topics at once\n",
    "queries = [\n",
    "    \"RAG retrieval augmented generation\",\n",
    "    \"vector embeddings\",\n",
    "    \"prompt engineering\"\n",
    "]\n",
    "\n",
    "arxiv_retriever_batch = ArxivRetriever(load_max_docs=3)\n",
    "batch_results = arxiv_retriever_batch.batch(queries)\n",
    "\n",
    "print(\"üìö Batch Search Results:\\n\")\n",
    "for query, docs in zip(queries, batch_results):\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"  ‚Üí Found {len(docs)} papers\")\n",
    "    if docs:\n",
    "        print(f\"  ‚Üí Top result: {docs[0].metadata.get('Title', 'N/A')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Understanding ArxivRetriever Metadata\n",
    "\n",
    "Each document returned by ArxivRetriever contains rich metadata:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'Published': '2023-06-15',           # Publication date\n",
    "    'Title': 'Paper Title',              # Full title\n",
    "    'Authors': 'Author1, Author2',       # Comma-separated authors\n",
    "    'Summary': 'Abstract text...',       # Paper abstract/summary\n",
    "    'entry_id': 'http://arxiv.org/...',  # Arxiv URL\n",
    "}\n",
    "```\n",
    "\n",
    "The `page_content` field contains the full abstract/summary of the paper.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='wikipedia'></a>\n",
    "## 4. WikipediaRetriever - General Knowledge üìñ\n",
    "\n",
    "### üî∞ BEGINNER: What is WikipediaRetriever?\n",
    "\n",
    "**WikipediaRetriever** searches and retrieves content from Wikipedia, the free encyclopedia with 6+ million articles.\n",
    "\n",
    "### Use Cases:\n",
    "- üåç General knowledge questions\n",
    "- üìö Quick facts and definitions\n",
    "- üèõÔ∏è Historical information\n",
    "- üßë‚Äçüî¨ Biographical data\n",
    "- üó∫Ô∏è Geographic information\n",
    "\n",
    "### Important Notes:\n",
    "- ‚ö†Ô∏è Wikipedia content is **community-edited** - verify critical information\n",
    "- ‚úÖ Great for general knowledge, not for specialized or proprietary data\n",
    "- üåê Supports multiple languages\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî∞ BEGINNER: Basic WikipediaRetriever Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL-NO: 6\n",
    "!uv pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL-NO: 7\n",
    "# Create a WikipediaRetriever instance\n",
    "# By default, it returns top 3 documents\n",
    "wiki_retriever = WikipediaRetriever(top_k_results=2)\n",
    "\n",
    "# Search for information on \"Python programming language\"\n",
    "query = \"Python programming language\"\n",
    "docs = wiki_retriever.invoke(query)\n",
    "\n",
    "print(f\"üìñ Found {len(docs)} Wikipedia articles on '{query}'\\n\")\n",
    "\n",
    "# Display first result\n",
    "print(\"=\" * 80)\n",
    "print(f\"Title: {docs[0].metadata.get('title', 'N/A')}\")\n",
    "print(f\"Source: {docs[0].metadata.get('source', 'N/A')}\")\n",
    "print(f\"\\nContent (first 600 chars):\\n{docs[0].page_content[:600]}...\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì INTERMEDIATE: Advanced WikipediaRetriever Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL-NO: 8\n",
    "# Advanced: Control number of results and document length\n",
    "wiki_retriever_advanced = WikipediaRetriever(\n",
    "    top_k_results=3,        # Get top 3 results\n",
    "    doc_content_chars_max=1000  # Limit content to 1000 characters per doc\n",
    ")\n",
    "\n",
    "# Search for \"Machine Learning\"\n",
    "query = \"Machine Learning\"\n",
    "docs = wiki_retriever_advanced.invoke(query)\n",
    "\n",
    "print(f\"üìñ Retrieved {len(docs)} Wikipedia articles\\n\")\n",
    "\n",
    "# Display all results\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"{i}. Title: {doc.metadata.get('title', 'N/A')}\")\n",
    "    print(f\"   Summary: {doc.metadata.get('summary', 'N/A')[:150]}...\")\n",
    "    print(f\"   Content length: {len(doc.page_content)} characters\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì INTERMEDIATE: Multilingual Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL-NO: 9\n",
    "# Search in different languages\n",
    "# Default is English ('en'), but you can specify other languages\n",
    "\n",
    "# Example: Search in Spanish\n",
    "wiki_retriever_es = WikipediaRetriever(\n",
    "    top_k_results=1,\n",
    "    lang=\"es\"  # Spanish Wikipedia\n",
    ")\n",
    "\n",
    "query = \"Inteligencia Artificial\"\n",
    "docs = wiki_retriever_es.invoke(query)\n",
    "\n",
    "print(f\"üåê Search in Spanish Wikipedia: '{query}'\\n\")\n",
    "print(f\"Title: {docs[0].metadata.get('title', 'N/A')}\")\n",
    "print(f\"Content preview:\\n{docs[0].page_content[:400]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì INTERMEDIATE: Batch Processing with WikipediaRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL-NO: 10\n",
    "# Batch search for multiple topics\n",
    "queries = [\n",
    "    \"Albert Einstein\",\n",
    "    \"Quantum Computing\",\n",
    "    \"Neural Networks\"\n",
    "]\n",
    "\n",
    "wiki_retriever_batch = WikipediaRetriever(top_k_results=1, doc_content_chars_max=500)\n",
    "batch_results = wiki_retriever_batch.batch(queries)\n",
    "\n",
    "print(\"üìñ Batch Wikipedia Search Results:\\n\")\n",
    "for query, docs in zip(queries, batch_results):\n",
    "    print(f\"Query: '{query}'\")\n",
    "    if docs:\n",
    "        print(f\"  ‚Üí Title: {docs[0].metadata.get('title', 'N/A')}\")\n",
    "        print(f\"  ‚Üí Summary: {docs[0].page_content[:200]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Understanding WikipediaRetriever Metadata\n",
    "\n",
    "Each document returned by WikipediaRetriever contains:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'title': 'Article Title',           # Wikipedia article title\n",
    "    'summary': 'Brief summary...',       # Short summary (if available)\n",
    "    'source': 'https://en.wikipedia...', # Full Wikipedia URL\n",
    "}\n",
    "```\n",
    "\n",
    "The `page_content` field contains the article text (up to `doc_content_chars_max` characters).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tavily'></a>\n",
    "## 5. TavilySearchAPIRetriever - Web Search üîç\n",
    "\n",
    "### üî∞ BEGINNER: What is TavilySearchAPIRetriever?\n",
    "\n",
    "**TavilySearchAPIRetriever** performs **real-time internet searches** using the Tavily Search API, optimized for AI applications.\n",
    "\n",
    "### Key Features:\n",
    "- üåê **Real-time web search** - Get the latest information from the internet\n",
    "- üéØ **AI-optimized** - Returns clean, relevant content for LLMs\n",
    "- üîí **Source attribution** - Includes URLs and metadata\n",
    "- ‚ö° **Fast & reliable** - Built specifically for AI use cases\n",
    "\n",
    "### Use Cases:\n",
    "- üì∞ Current events and news\n",
    "- üíπ Stock prices and market data\n",
    "- üå¶Ô∏è Weather information\n",
    "- üè¢ Company information\n",
    "- üîß Technical documentation and tutorials\n",
    "\n",
    "### Getting Started:\n",
    "1. Sign up at https://tavily.com/ (free tier available)\n",
    "2. Get your API key\n",
    "3. Add to `.env` file: `TAVILY_API_KEY=your_api_key`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî∞ BEGINNER: Basic TavilySearchAPIRetriever Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL-NO: 11\n",
    "!uv pip install tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL-NO: 12\n",
    "# Create a TavilySearchAPIRetriever instance\n",
    "# Make sure TAVILY_API_KEY is set in your .env file\n",
    "\n",
    "tavily_retriever = TavilySearchAPIRetriever(k=3)  # Return top 3 results\n",
    "\n",
    "# Search for \"latest developments in artificial intelligence 2024\"\n",
    "query = \"latest developments in artificial intelligence 2024\"\n",
    "docs = tavily_retriever.invoke(query)\n",
    "\n",
    "print(f\"üîç Found {len(docs)} web results for '{query}'\\n\")\n",
    "\n",
    "# Display first result\n",
    "print(\"=\" * 80)\n",
    "print(f\"Source: {docs[0].metadata.get('source', 'N/A')}\")\n",
    "print(f\"\\nContent (first 500 chars):\\n{docs[0].page_content[:500]}...\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì INTERMEDIATE: Advanced TavilySearchAPIRetriever Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL-NO: 13\n",
    "# Advanced: Control search depth and domain filtering\n",
    "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
    "\n",
    "# Advanced configuration\n",
    "tavily_retriever_advanced = TavilySearchAPIRetriever(\n",
    "    k=5,  # Return top 5 results\n",
    "    # search_depth=\"advanced\",  # \"basic\" or \"advanced\" (more thorough)\n",
    "    # include_domains=[\"github.com\", \"stackoverflow.com\"],  # Filter to specific domains\n",
    "    # exclude_domains=[\"example.com\"]  # Exclude specific domains\n",
    ")\n",
    "\n",
    "# Search for \"LangChain tutorials\"\n",
    "query = \"LangChain tutorials\"\n",
    "docs = tavily_retriever_advanced.invoke(query)\n",
    "\n",
    "print(f\"üîç Retrieved {len(docs)} web results\\n\")\n",
    "\n",
    "# Display all results with sources\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"{i}. Source: {doc.metadata.get('source', 'N/A')}\")\n",
    "    print(f\"   Content preview: {doc.page_content[:200]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì INTERMEDIATE: Real-Time Information Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL-NO: 14\n",
    "# Example: Get current information (news, weather, stock prices, etc.)\n",
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.now().strftime(\"%B %d, %Y\")\n",
    "\n",
    "# Real-time queries\n",
    "queries = [\n",
    "    f\"latest AI news {current_date}\",\n",
    "    \"current weather in San Francisco\",\n",
    "    \"NVIDIA stock price today\"\n",
    "]\n",
    "\n",
    "tavily_realtime = TavilySearchAPIRetriever(k=2)\n",
    "\n",
    "print(f\"üïê Real-Time Information (as of {current_date}):\\n\")\n",
    "\n",
    "for query in queries:\n",
    "    docs = tavily_realtime.invoke(query)\n",
    "    print(f\"Query: '{query}'\")\n",
    "    if docs:\n",
    "        print(f\"  ‚Üí {docs[0].page_content[:250]}...\")\n",
    "        print(f\"  ‚Üí Source: {docs[0].metadata.get('source', 'N/A')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Understanding TavilySearchAPIRetriever Metadata\n",
    "\n",
    "Each document returned by TavilySearchAPIRetriever contains:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'source': 'https://example.com/...',  # Source URL\n",
    "    'score': 0.95,                         # Relevance score (0-1)\n",
    "    'title': 'Page Title',                 # Web page title (if available)\n",
    "}\n",
    "```\n",
    "\n",
    "The `page_content` field contains the extracted text content from the web page.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rag'></a>\n",
    "## 6. Integration with RAG Chains üîó\n",
    "\n",
    "Now let's combine external retrievers with LLMs to build powerful **Retrieval-Augmented Generation (RAG)** systems!\n",
    "\n",
    "### üî∞ BEGINNER: Simple QA Chain with External Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to format documents\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL-NO: 15\n",
    "# Build a simple RAG chain using WikipediaRetriever\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Initialize components\n",
    "wiki_retriever = WikipediaRetriever(top_k_results=2, doc_content_chars_max=2000)\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\", temperature=0)\n",
    "\n",
    "# Create prompt template\n",
    "template = \"\"\"Answer the question based on the following context from Wikipedia:\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "# Build the RAG chain using LCEL\n",
    "rag_chain = (\n",
    "    {\n",
    "      \"context\": wiki_retriever | format_docs, \n",
    "      \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Ask a question\n",
    "question = \"What is quantum computing and how does it work?\"\n",
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì INTERMEDIATE: Multi-Source RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL-NO: 16\n",
    "# Advanced: Combine multiple retrievers for comprehensive answers\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# Initialize multiple retrievers\n",
    "arxiv_retriever = ArxivRetriever(load_max_docs=2)\n",
    "wiki_retriever = WikipediaRetriever(top_k_results=2, doc_content_chars_max=1500)\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\", temperature=0)\n",
    "\n",
    "# Function to combine results from multiple retrievers\n",
    "def multi_retriever(query):\n",
    "    \"\"\"Retrieve from multiple sources and combine results.\"\"\"\n",
    "\n",
    "    print(f\"Passing query:{query} to arxiv and wikipedia...\")\n",
    "    arxiv_docs = arxiv_retriever.invoke(query)\n",
    "    wiki_docs = wiki_retriever.invoke(query)\n",
    "    \n",
    "    # Combine and format\n",
    "    all_docs = []\n",
    "    \n",
    "    if arxiv_docs:\n",
    "        all_docs.append(\"=== Academic Papers (ArXiv) ===\")\n",
    "        all_docs.extend([doc.page_content[:500] for doc in arxiv_docs])\n",
    "    \n",
    "    if wiki_docs:\n",
    "        all_docs.append(\"\\n=== General Knowledge (Wikipedia) ===\")\n",
    "        all_docs.extend([doc.page_content[:500] for doc in wiki_docs])\n",
    "    \n",
    "    return \"\\n\\n\".join(all_docs)\n",
    "\n",
    "# Create multi-source RAG chain\n",
    "multi_source_template = \"\"\"Answer the question using information from multiple sources below:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Provide a comprehensive answer that synthesizes information from both academic and general sources:\"\"\"\n",
    "\n",
    "multi_prompt = ChatPromptTemplate.from_template(multi_source_template)\n",
    "\n",
    "multi_rag_chain = (\n",
    "    {\n",
    "      \"context\": multi_retriever, \n",
    "      \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | multi_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Ask a question\n",
    "question = \"What are transformers in machine learning?\"\n",
    "answer = multi_rag_chain.invoke(question)\n",
    "\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(f\"Answer (from multiple sources):\\n{answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì INTERMEDIATE: Real-Time RAG with TavilySearchAPIRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL-NO: 17\n",
    "# Build a RAG chain that uses real-time web search\n",
    "tavily_retriever = TavilySearchAPIRetriever(k=3)\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Create prompt for real-time information\n",
    "realtime_template = \"\"\"Based on the latest information from the web:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Provide an up-to-date answer having atleast 500 words with source attribution:\"\"\"\n",
    "\n",
    "realtime_prompt = ChatPromptTemplate.from_template(realtime_template)\n",
    "\n",
    "# Build real-time RAG chain\n",
    "realtime_rag_chain = (\n",
    "    {\"context\": tavily_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | realtime_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Ask a current events question\n",
    "question = \"What are the latest developments in AI regulation?\"\n",
    "answer = realtime_rag_chain.invoke(question)\n",
    "\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(f\"Answer (from real-time web search):\\n{answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='comparison'></a>\n",
    "## 7. Comparison & Use Cases üìä\n",
    "\n",
    "### Retriever Comparison Table\n",
    "\n",
    "| Feature | ArxivRetriever | WikipediaRetriever | TavilySearchAPIRetriever |\n",
    "|---------|----------------|-------------------|-------------------------|\n",
    "| **Data Source** | Academic papers (arxiv.org) | Wikipedia articles | Real-time web search |\n",
    "| **API Key Required** | ‚ùå No | ‚ùå No | ‚úÖ Yes (free tier) |\n",
    "| **Data Freshness** | Recent research | Regularly updated | Real-time |\n",
    "| **Best For** | Academic research, ML papers | General knowledge, definitions | Current events, news |\n",
    "| **Content Type** | Research papers, abstracts | Encyclopedia articles | Web pages, news |\n",
    "| **Default Results** | 3 papers | 3 articles | 5 results |\n",
    "| **Multilingual** | ‚ùå No | ‚úÖ Yes (300+ languages) | ‚úÖ Yes |\n",
    "| **Metadata** | Title, Authors, Published date | Title, Summary, URL | Source URL, Score |\n",
    "| **Rate Limits** | Moderate | Moderate | API-dependent |\n",
    "| **Cost** | üÜì Free | üÜì Free | üÜì Free tier + paid |\n",
    "\n",
    "---\n",
    "\n",
    "### When to Use Each Retriever\n",
    "\n",
    "#### ‚úÖ Use **ArxivRetriever** when:\n",
    "- You need peer-reviewed academic research\n",
    "- You're building an AI/ML research assistant\n",
    "- You want the latest scientific papers\n",
    "- You need citations and author information\n",
    "\n",
    "#### ‚úÖ Use **WikipediaRetriever** when:\n",
    "- You need general knowledge and definitions\n",
    "- You want historical or biographical information\n",
    "- You're building an educational chatbot\n",
    "- You need multilingual support\n",
    "- You want reliable, community-edited content\n",
    "\n",
    "#### ‚úÖ Use **TavilySearchAPIRetriever** when:\n",
    "- You need real-time, up-to-date information\n",
    "- You're answering current events questions\n",
    "- You want to search the broader internet\n",
    "- You need to filter by specific domains\n",
    "- Your use case requires the latest data\n",
    "\n",
    "---\n",
    "\n",
    "### Combining Retrievers (Hybrid Approach)\n",
    "\n",
    "For the most comprehensive RAG system:\n",
    "\n",
    "```python\n",
    "# Pseudo-code for hybrid retrieval\n",
    "if query_type == \"academic\":\n",
    "    use ArxivRetriever\n",
    "elif query_type == \"general_knowledge\":\n",
    "    use WikipediaRetriever\n",
    "elif query_type == \"current_events\":\n",
    "    use TavilySearchAPIRetriever\n",
    "else:\n",
    "    # Use multiple retrievers and combine results\n",
    "    combine(ArxivRetriever, WikipediaRetriever, TavilySearchAPIRetriever)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='best-practices'></a>\n",
    "## 8. Best Practices üí°\n",
    "\n",
    "### General Best Practices\n",
    "\n",
    "#### 1. **Handle Errors Gracefully**\n",
    "\n",
    "```python\n",
    "try:\n",
    "    docs = retriever.invoke(query)\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving documents: {e}\")\n",
    "    docs = []  # Fallback to empty list\n",
    "```\n",
    "\n",
    "#### 2. **Set Appropriate Limits**\n",
    "\n",
    "```python\n",
    "# Don't retrieve too many documents (costs, latency)\n",
    "arxiv_retriever = ArxivRetriever(load_max_docs=3)  # ‚úÖ Good\n",
    "arxiv_retriever = ArxivRetriever(load_max_docs=100)  # ‚ùå Too many\n",
    "```\n",
    "\n",
    "#### 3. **Cache Results for Repeated Queries**\n",
    "\n",
    "```python\n",
    "# Use a simple cache to avoid redundant API calls\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=100)\n",
    "def cached_search(query: str):\n",
    "    return retriever.invoke(query)\n",
    "```\n",
    "\n",
    "#### 4. **Verify Source Attribution**\n",
    "\n",
    "```python\n",
    "# Always include sources in your responses\n",
    "for doc in docs:\n",
    "    print(f\"Source: {doc.metadata.get('source', 'N/A')}\")\n",
    "```\n",
    "\n",
    "#### 5. **Combine with Vector Store Retrievers**\n",
    "\n",
    "```python\n",
    "# Use external retrievers for general knowledge\n",
    "# Use vector stores for your proprietary data\n",
    "def hybrid_retrieve(query):\n",
    "    external_docs = wiki_retriever.invoke(query)\n",
    "    internal_docs = vector_store.similarity_search(query)\n",
    "    return external_docs + internal_docs\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Retriever-Specific Best Practices\n",
    "\n",
    "#### ArxivRetriever:\n",
    "- ‚úÖ Use specific search terms (e.g., \"BERT transformers\" vs \"AI\")\n",
    "- ‚úÖ Limit results to 3-5 papers for LLM context\n",
    "- ‚úÖ Extract metadata for citations\n",
    "- ‚ùå Don't use for non-academic queries\n",
    "\n",
    "#### WikipediaRetriever:\n",
    "- ‚úÖ Use for general knowledge, not specialized topics\n",
    "- ‚úÖ Set `doc_content_chars_max` to avoid huge documents\n",
    "- ‚úÖ Verify information for critical use cases\n",
    "- ‚ùå Don't rely on Wikipedia for real-time information\n",
    "\n",
    "#### TavilySearchAPIRetriever:\n",
    "- ‚úÖ Monitor API usage (rate limits, costs)\n",
    "- ‚úÖ Use for time-sensitive queries\n",
    "- ‚úÖ Filter by domain for specific sources\n",
    "- ‚ùå Don't use for queries that don't need real-time data\n",
    "\n",
    "---\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "1. **Use `.batch()` for multiple queries**\n",
    "   ```python\n",
    "   # ‚úÖ Efficient\n",
    "   results = retriever.batch([q1, q2, q3])\n",
    "   \n",
    "   # ‚ùå Inefficient\n",
    "   results = [retriever.invoke(q) for q in [q1, q2, q3]]\n",
    "   ```\n",
    "\n",
    "2. **Limit document length for LLM context**\n",
    "   ```python\n",
    "   # Truncate long documents to fit LLM context window\n",
    "   docs = [Document(page_content=doc.page_content[:2000], metadata=doc.metadata) \n",
    "           for doc in raw_docs]\n",
    "   ```\n",
    "\n",
    "3. **Use async methods for concurrent retrieval** (if supported)\n",
    "   ```python\n",
    "   # For async-compatible retrievers\n",
    "   import asyncio\n",
    "   docs = await retriever.ainvoke(query)\n",
    "   ```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "## 9. Summary & Exercises üìù\n",
    "\n",
    "### üéØ What You Learned\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "‚úÖ **External Index Retrievers** - Search over external data sources (internet, databases)\n",
    "\n",
    "‚úÖ **ArxivRetriever** - Retrieve academic papers from arxiv.org\n",
    "   - Use cases: Research, ML papers, citations\n",
    "   - Methods: `.invoke()`, `.batch()`\n",
    "   - Metadata: Title, Authors, Published date\n",
    "\n",
    "‚úÖ **WikipediaRetriever** - Access Wikipedia articles\n",
    "   - Use cases: General knowledge, definitions, history\n",
    "   - Features: Multilingual support, customizable length\n",
    "   - Metadata: Title, Summary, Source URL\n",
    "\n",
    "‚úÖ **TavilySearchAPIRetriever** - Real-time web search\n",
    "   - Use cases: Current events, news, real-time data\n",
    "   - Features: Domain filtering, search depth control\n",
    "   - Metadata: Source URL, Relevance score\n",
    "\n",
    "‚úÖ **RAG Integration** - Combined external retrievers with LLMs\n",
    "   - Built simple QA chains\n",
    "   - Created multi-source RAG systems\n",
    "   - Implemented real-time information retrieval\n",
    "\n",
    "‚úÖ **Best Practices** - Error handling, caching, source attribution\n",
    "\n",
    "---\n",
    "\n",
    "### üí™ Practice Exercises\n",
    "\n",
    "#### Exercise 1: Academic Research Assistant (üî∞ Beginner)\n",
    "Create a RAG chain that:\n",
    "- Uses `ArxivRetriever` to find papers on \"deep learning\"\n",
    "- Extracts the top 3 paper titles and authors\n",
    "- Summarizes each paper's abstract using an LLM\n",
    "\n",
    "#### Exercise 2: Wikipedia Fact Checker (üî∞ Beginner)\n",
    "Build a system that:\n",
    "- Takes a statement as input (e.g., \"Python was created in 1991\")\n",
    "- Uses `WikipediaRetriever` to search for relevant articles\n",
    "- Uses an LLM to verify if the statement is accurate\n",
    "\n",
    "#### Exercise 3: Multi-Source News Aggregator (üéì Intermediate)\n",
    "Create a RAG chain that:\n",
    "- Uses `TavilySearchAPIRetriever` to get latest AI news\n",
    "- Uses `WikipediaRetriever` to get background on AI topics\n",
    "- Combines both sources to provide a comprehensive news summary\n",
    "\n",
    "#### Exercise 4: Hybrid Retrieval System (üéì Intermediate)\n",
    "Build a system that:\n",
    "- Classifies queries into \"academic\", \"general\", or \"current_events\"\n",
    "- Routes to the appropriate retriever based on query type\n",
    "- Returns results from the most relevant source\n",
    "\n",
    "#### Exercise 5: Multilingual Knowledge Base (üöÄ Advanced)\n",
    "Create a system that:\n",
    "- Detects the language of the user's query\n",
    "- Uses `WikipediaRetriever` with the appropriate language setting\n",
    "- Returns answers in the user's language\n",
    "\n",
    "---\n",
    "\n",
    "### üîó Next Steps\n",
    "\n",
    "- **Notebook 09**: Advanced Retrieval Techniques (Hybrid Search, Re-ranking)\n",
    "- **Notebook 10**: Production RAG Systems (Caching, Monitoring, Scaling)\n",
    "- **LangChain Documentation**: https://python.langchain.com/docs/integrations/retrievers/\n",
    "\n",
    "---\n",
    "\n",
    "### üìö Additional Resources\n",
    "\n",
    "- **ArXiv**: https://arxiv.org/\n",
    "- **Wikipedia API**: https://www.mediawiki.org/wiki/API:Main_page\n",
    "- **Tavily API**: https://tavily.com/\n",
    "- **LangChain Retrievers**: https://python.langchain.com/docs/modules/data_connection/retrievers/\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** üéâ You've mastered external index retrievers in LangChain!\n",
    "\n",
    "You can now build RAG systems that access:\n",
    "- üìÑ Academic research (ArXiv)\n",
    "- üìñ General knowledge (Wikipedia)\n",
    "- üåê Real-time web data (Tavily)\n",
    "\n",
    "Keep experimenting and building amazing AI applications! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
